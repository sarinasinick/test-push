{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "version": "2.7.18",
      "name": "python",
      "pygments_lexer": "ipython2",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 2,
        "name": "ipython"
      }
    },
    "creator": "admin",
    "createdOn": 1644274392947,
    "hide_input": false,
    "modifiedBy": "admin",
    "customFields": {},
    "tags": []
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pylab inline"
      ],
      "outputs": []
    },
    {
      "execution_count": 1,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nimport dataiku.spark as dkuspark\nimport pyspark\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load PySpark\nsc \u003d pyspark.SparkContext.getOrCreate()\nsqlContext \u003d SQLContext(sc)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example: Read the descriptor of a Dataiku dataset\nmydataset \u003d dataiku.Dataset(\"mydataset\")\n# And read it as a Spark dataframe\ndf \u003d dkuspark.get_dataframe(sqlContext, mydataset)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example: Get the count of records in the dataframe\ndf.count()"
      ],
      "outputs": []
    },
    {
      "execution_count": 20,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pprint\nclient \u003d dataiku.api_client()\nprojects \u003d client.list_project_keys()\n\nfor p in projects:\n    project \u003d client.get_project(p)\n    datasets \u003d project.list_datasets()\n    for d in datasets:\n        dataset \u003d project.get_dataset(d[\"name\"])\n        # if the dataset is currently synchronized\n        settings \u003d dataset.get_settings()\n        raw_settings \u003d settings.get_raw()\n        if \u0027metastoreSynchronizationEnabled\u0027 in raw_settings[\u0027params\u0027]:\n            try:\n                print(\u0027synchronizng dataset \u0027, d[\u0027name\u0027])\n                # check if a dataset with synchronization on does *not* have a database set\n                if \u0027metastoreDatabaseName\u0027 not in raw_settings[\u0027params\u0027]:\n                    if some_logical_check:\n                        default_db \u003d \u0027some_default_database_value\u0027\n                    elif some_other_check: \n                        default_db \u003d \u0027some_other_default_database_value\u0027\n                    else:\n                        default_db \u003d \u0027else_default_db\u0027\n\n                    # add some logic to determine what the correct database to add to the dataset is \n                    # then set the database in the dataset settings \n                    raw_settings[\u0027params\u0027][\u0027metastoreDatabaseName\u0027] \u003d default_db\n                    settings.save()\n                    print(\u0027updated metastore db\u0027)\n                # synchronize the metastore either way \n                dataset.synchronize_hive_metastore()\n            except:\n                print(\u0027failed\u0027)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(\u0027synchronizng dataset \u0027, u\u0027adult_1_copy\u0027)\nfailed\n(\u0027synchronizng dataset \u0027, u\u0027adult_1_copy_prepared\u0027)\nupdated metastore db\nfailed\n(\u0027synchronizng dataset \u0027, u\u0027adult_1_prepared\u0027)\nupdated metastore db\nfailed\n(\u0027synchronizng dataset \u0027, u\u0027adult_1_prepared_a\u0027)\n(\u0027synchronizng dataset \u0027, u\u0027adult_1_prepared_a_prepared\u0027)\nupdated metastore db\nfailed\n(\u0027synchronizng dataset \u0027, u\u0027adult__1__prepared\u0027)\nupdated metastore db\n(\u0027synchronizng dataset \u0027, u\u0027adult_prepared\u0027)\nupdated metastore db\nfailed\n(\u0027synchronizng dataset \u0027, u\u0027crm_and_web_history_enriched_stacked\u0027)\nfailed\n(\u0027synchronizng dataset \u0027, u\u0027datetype_test\u0027)\nupdated metastore db\n(\u0027synchronizng dataset \u0027, u\u0027myython\u0027)\n(\u0027synchronizng dataset \u0027, u\u0027pttn_test_group_1_copy\u0027)\nupdated metastore db\n(\u0027synchronizng dataset \u0027, u\u0027pttn_test_group_1_copy_by_prttn_trade_dt\u0027)\nupdated metastore db\n(\u0027synchronizng dataset \u0027, u\u0027pttn_test_group_2_by_prttn_trade_dt\u0027)\nupdated metastore db\n(\u0027synchronizng dataset \u0027, u\u0027pttn_test_group_2_by_prttn_tras\u0027)\nupdated metastore db\n(\u0027synchronizng dataset \u0027, u\u0027pttn_test_group_2_copy\u0027)\nupdated metastore db\n(\u0027synchronizng dataset \u0027, u\u0027pttn_test_group_2_copy_1\u0027)\nupdated metastore db\n(\u0027synchronizng dataset \u0027, u\u0027pttn_test_group_2_copy_1_prepared\u0027)\nupdated metastore db\n(\u0027synchronizng dataset \u0027, u\u0027pttn_test_group_2_copy_by_prttn_trade_dt\u0027)\nupdated metastore db\n(\u0027synchronizng dataset \u0027, u\u0027pttn_test_group_2_copy_prepared\u0027)\nupdated metastore db\n(\u0027synchronizng dataset \u0027, u\u0027sample_data_prepared\u0027)\nupdated metastore db\n(\u0027synchronizng dataset \u0027, u\u0027test\u0027)\nupdated metastore db\n(\u0027synchronizng dataset \u0027, u\u0027test_for_spaces_1_prepared\u0027)\nupdated metastore db\nfailed\n(\u0027synchronizng dataset \u0027, u\u0027test_for_spaces_prepared\u0027)\nupdated metastore db\nfailed\n(\u0027synchronizng dataset \u0027, u\u0027test_pyspark\u0027)\nupdated metastore db\nfailed\n(\u0027synchronizng dataset \u0027, u\u0027testorc\u0027)\nupdated metastore db\nfailed\n"
        }
      ]
    },
    {
      "execution_count": 1,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset.get_settings().get_raw()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "evalue": "name \u0027dataset\u0027 is not defined",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-1-f3beefb079b4\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_settings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name \u0027dataset\u0027 is not defined"
          ],
          "ename": "NameError"
        }
      ]
    },
    {
      "execution_count": 18,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "raw_settings \u003dproject.get_dataset(\u0027adult_1_prepared_a\u0027).get_settings().get_raw()"
      ],
      "outputs": []
    },
    {
      "execution_count": 20,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if \u0027metastoreSynchronizationEnabled\u0027 in raw_settings[\u0027params\u0027]:\n    print(\u0027hi\u0027)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "hi\n"
        }
      ]
    },
    {
      "execution_count": 3,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pprint\nclient \u003d dataiku.api_client()\nprojects \u003d client.list_project_keys()\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 13,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for p in projects:\n    project \u003d client.get_project(p)\n    datasets \u003d project.list_datasets()\n    for d in datasets:\n        dataset \u003d project.get_dataset(d[\"name\"])\n        # if the dataset is currently synchronized\n        settings \u003d dataset.get_settings()\n        \n        raw_settings \u003d settings.get_raw()\n        if \u0027metastoreSynchronizationEnabled\u0027 in raw_settings[\u0027params\u0027]:\n            d_test \u003d dataset"
      ],
      "outputs": []
    },
    {
      "execution_count": 15,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "d_test.get_settings().get_raw()[\u0027params\u0027]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "metadata": {},
          "data": {
            "text/plain": "{u\u0027bucket\u0027: u\u0027dku-sarina-support\u0027,\n u\u0027connection\u0027: u\u0027s3\u0027,\n u\u0027filesSelectionRules\u0027: {u\u0027excludeRules\u0027: [],\n  u\u0027explicitFiles\u0027: [],\n  u\u0027includeRules\u0027: [],\n  u\u0027mode\u0027: u\u0027ALL\u0027},\n u\u0027metastoreSynchronizationEnabled\u0027: True,\n u\u0027metastoreTableName\u0027: u\u0027testorc\u0027,\n u\u0027notReadyIfEmpty\u0027: False,\n u\u0027path\u0027: u\u0027/dataiku/${projectKey}/testorc\u0027}"
          },
          "execution_count": 15
        }
      ]
    },
    {
      "execution_count": 17,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "project.get_dataset(\u0027crm_and_web_history_enriched_stacked\u0027).get_settings().get_raw()[\u0027params\u0027]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "metadata": {},
          "data": {
            "text/plain": "{u\u0027bucket\u0027: u\u0027dku-sarina-support\u0027,\n u\u0027connection\u0027: u\u0027s3\u0027,\n u\u0027filesSelectionRules\u0027: {u\u0027excludeRules\u0027: [],\n  u\u0027explicitFiles\u0027: [],\n  u\u0027includeRules\u0027: [],\n  u\u0027mode\u0027: u\u0027ALL\u0027},\n u\u0027metastoreDatabaseName\u0027: u\u0027test_db\u0027,\n u\u0027metastoreSynchronizationEnabled\u0027: True,\n u\u0027metastoreTableName\u0027: u\u0027crm_and_web_history_enriched_stacked\u0027,\n u\u0027notReadyIfEmpty\u0027: False,\n u\u0027path\u0027: u\u0027/dataiku/${projectKey}/crm_and_web_history_enriched_stacked\u0027}"
          },
          "execution_count": 17
        }
      ]
    },
    {
      "execution_count": 2,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pprint\nclient \u003d dataiku.api_client()\nprojects \u003d client.list_project_keys()\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 3,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "project \u003d client.get_default_project()"
      ],
      "outputs": []
    },
    {
      "execution_count": 4,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset \u003d project.get_dataset(\u0027sample_data\u0027)"
      ],
      "outputs": []
    },
    {
      "execution_count": 6,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "s \u003d dataset.get_settings()"
      ],
      "outputs": []
    },
    {
      "execution_count": 7,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dazt"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "metadata": {},
          "data": {
            "text/plain": "{u\u0027checklists\u0027: {u\u0027checklists\u0027: []},\n u\u0027creationTag\u0027: {u\u0027lastModifiedBy\u0027: {u\u0027login\u0027: u\u0027admin\u0027},\n  u\u0027lastModifiedOn\u0027: 1643252418091,\n  u\u0027versionNumber\u0027: 0},\n u\u0027customFields\u0027: {},\n u\u0027customMeta\u0027: {u\u0027kv\u0027: {}},\n u\u0027dkuProperties\u0027: [],\n u\u0027flowOptions\u0027: {u\u0027crossProjectBuildBehavior\u0027: u\u0027DEFAULT\u0027,\n  u\u0027rebuildBehavior\u0027: u\u0027NORMAL\u0027,\n  u\u0027virtualizable\u0027: False},\n u\u0027formatParams\u0027: {u\u0027arrayMapFormat\u0027: u\u0027json\u0027,\n  u\u0027charset\u0027: u\u0027utf-8\u0027,\n  u\u0027compress\u0027: u\u0027\u0027,\n  u\u0027dateSerializationFormat\u0027: u\u0027ISO\u0027,\n  u\u0027escapeChar\u0027: u\u0027\\\\\u0027,\n  u\u0027fileReadFailureBehavior\u0027: u\u0027FAIL\u0027,\n  u\u0027hiveSeparators\u0027: [u\u0027\\x02\u0027,\n   u\u0027\\x03\u0027,\n   u\u0027\\x04\u0027,\n   u\u0027\\x05\u0027,\n   u\u0027\\x06\u0027,\n   u\u0027\\x07\u0027,\n   u\u0027\\x08\u0027],\n  u\u0027normalizeBooleans\u0027: False,\n  u\u0027normalizeDoubles\u0027: True,\n  u\u0027parseHeaderRow\u0027: False,\n  u\u0027probableNumberOfRecords\u0027: 6,\n  u\u0027quoteChar\u0027: u\u0027\"\u0027,\n  u\u0027readAdditionalColumnsBehavior\u0027: u\u0027INSERT_IN_DATA_WARNING\u0027,\n  u\u0027readDataTypeMismatchBehavior\u0027: u\u0027DISCARD_WARNING\u0027,\n  u\u0027readMissingColumnsBehavior\u0027: u\u0027DISCARD_SILENT\u0027,\n  u\u0027separator\u0027: u\u0027,\u0027,\n  u\u0027skipRowsAfterHeader\u0027: 0,\n  u\u0027skipRowsBeforeHeader\u0027: 1,\n  u\u0027style\u0027: u\u0027excel\u0027,\n  u\u0027writeDataTypeMismatchBehavior\u0027: u\u0027DISCARD_WARNING\u0027},\n u\u0027formatType\u0027: u\u0027csv\u0027,\n u\u0027managed\u0027: False,\n u\u0027metrics\u0027: {u\u0027displayedState\u0027: {u\u0027columns\u0027: [],\n   u\u0027metrics\u0027: [u\u0027basic:COUNT_COLUMNS\u0027,\n    u\u0027basic:COUNT_FILES\u0027,\n    u\u0027basic:SIZE\u0027,\n    u\u0027records:COUNT_RECORDS\u0027]},\n  u\u0027engineConfig\u0027: {u\u0027basic\u0027: {},\n   u\u0027dss\u0027: {u\u0027active\u0027: True,\n    u\u0027selection\u0027: {u\u0027filter\u0027: {u\u0027distinct\u0027: False, u\u0027enabled\u0027: False},\n     u\u0027latestPartitionsN\u0027: 1,\n     u\u0027maxReadUncompressedBytes\u0027: -1,\n     u\u0027maxRecords\u0027: -1,\n     u\u0027ordering\u0027: {u\u0027enabled\u0027: False, u\u0027rules\u0027: []},\n     u\u0027partitionSelectionMethod\u0027: u\u0027ALL\u0027,\n     u\u0027samplingMethod\u0027: u\u0027FULL\u0027,\n     u\u0027targetRatio\u0027: 0.02,\n     u\u0027useMemTable\u0027: False,\n     u\u0027withinFirstN\u0027: -1}},\n   u\u0027hive\u0027: {u\u0027active\u0027: True, u\u0027extraConf\u0027: []},\n   u\u0027impala\u0027: {u\u0027active\u0027: True},\n   u\u0027padRunsWithMetrics\u0027: False,\n   u\u0027python\u0027: {},\n   u\u0027spark\u0027: {u\u0027active\u0027: True, u\u0027extraConf\u0027: []},\n   u\u0027sql\u0027: {u\u0027active\u0027: True}},\n  u\u0027probes\u0027: [{u\u0027computeOnBuildMode\u0027: u\u0027PARTITION\u0027,\n    u\u0027configuration\u0027: {},\n    u\u0027enabled\u0027: True,\n    u\u0027meta\u0027: {u\u0027level\u0027: 0, u\u0027name\u0027: u\u0027Basic data\u0027},\n    u\u0027type\u0027: u\u0027basic\u0027},\n   {u\u0027computeOnBuildMode\u0027: u\u0027NO\u0027,\n    u\u0027configuration\u0027: {},\n    u\u0027enabled\u0027: True,\n    u\u0027meta\u0027: {u\u0027level\u0027: 0, u\u0027name\u0027: u\u0027Record count\u0027},\n    u\u0027type\u0027: u\u0027records\u0027}]},\n u\u0027metricsChecks\u0027: {u\u0027checks\u0027: [],\n  u\u0027displayedState\u0027: {u\u0027checks\u0027: []},\n  u\u0027runOnBuild\u0027: False},\n u\u0027name\u0027: u\u0027sample_data\u0027,\n u\u0027params\u0027: {u\u0027connection\u0027: u\u0027s3\u0027,\n  u\u0027filesSelectionRules\u0027: {u\u0027excludeRules\u0027: [],\n   u\u0027explicitFiles\u0027: [],\n   u\u0027includeRules\u0027: [],\n   u\u0027mode\u0027: u\u0027ALL\u0027},\n  u\u0027notReadyIfEmpty\u0027: False,\n  u\u0027uploadFSProviderType\u0027: u\u0027S3\u0027,\n  u\u0027uploadedConfig\u0027: {u\u0027bucket\u0027: u\u0027dku-sarina-support\u0027,\n   u\u0027connection\u0027: u\u0027s3\u0027,\n   u\u0027filesSelectionRules\u0027: {u\u0027excludeRules\u0027: [],\n    u\u0027explicitFiles\u0027: [],\n    u\u0027includeRules\u0027: [],\n    u\u0027mode\u0027: u\u0027ALL\u0027},\n   u\u0027metastoreSynchronizationEnabled\u0027: True,\n   u\u0027metastoreTableName\u0027: u\u0027sample_data\u0027,\n   u\u0027notReadyIfEmpty\u0027: False,\n   u\u0027path\u0027: u\u0027/dataiku/uploads/${projectKey}/sample_data\u0027}},\n u\u0027partitioning\u0027: {u\u0027considerMissingRequestedPartitionsAsEmpty\u0027: False,\n  u\u0027dimensions\u0027: [],\n  u\u0027ignoreNonMatchingFile\u0027: False},\n u\u0027projectKey\u0027: u\u0027DKU_TSHIRTS\u0027,\n u\u0027readWriteOptions\u0027: {u\u0027defaultReadOrdering\u0027: {u\u0027enabled\u0027: False,\n   u\u0027rules\u0027: []},\n  u\u0027forceSingleOutputFile\u0027: False,\n  u\u0027preserveOrder\u0027: False,\n  u\u0027writeBuckets\u0027: 1},\n u\u0027schema\u0027: {u\u0027columns\u0027: [{u\u0027name\u0027: u\u0027col_0\u0027, u\u0027type\u0027: u\u0027string\u0027},\n   {u\u0027name\u0027: u\u0027col_1\u0027, u\u0027type\u0027: u\u0027string\u0027},\n   {u\u0027name\u0027: u\u0027col_2\u0027, u\u0027type\u0027: u\u0027string\u0027},\n   {u\u0027name\u0027: u\u0027col_3\u0027, u\u0027type\u0027: u\u0027string\u0027},\n   {u\u0027name\u0027: u\u0027col_4\u0027, u\u0027type\u0027: u\u0027string\u0027},\n   {u\u0027name\u0027: u\u0027col_5\u0027, u\u0027type\u0027: u\u0027string\u0027}],\n  u\u0027userModified\u0027: True},\n u\u0027smartName\u0027: u\u0027sample_data\u0027,\n u\u0027tags\u0027: [],\n u\u0027type\u0027: u\u0027UploadedFiles\u0027,\n u\u0027versionTag\u0027: {u\u0027lastModifiedBy\u0027: {u\u0027login\u0027: u\u0027admin\u0027},\n  u\u0027lastModifiedOn\u0027: 1643252474666,\n  u\u0027versionNumber\u0027: 4}}"
          },
          "execution_count": 7
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}